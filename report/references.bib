@article{Guo2009_DCM,
	abstract = {Many tasks that leverage web search users' implicit feedback rely on a proper and unbiased interpretation of user clicks. Previous eye-tracking experiments and studies on explaining position-bias of user clicks provide a spectrum of hypotheses and models on how an average user examines and possibly clicks web documents returned by a search engine with respect to the submitted query. In this paper, we attempt to close the gap between previous work, which studied how to model a single click, and the reality that multiple clicks on web documents in a single result page are not uncommon. Specifically, we present two multiple-click models: the independent click model (ICM) which is reformulated from previous work, and the dependent click model (DCM) which takes into consideration dependencies between multiple clicks. Both models can be efficiently learned with linear time and space complexities. More importantly, they can be incrementally updated as new click logs flow in. These are well-demanded properties in reality. We systematically evaluate the two models on click logs obtained in July 2008 from a major commercial search engine. The data set, after preprocessing, contains over 110 thousand distinct queries and 8.8 million query sessions. Extensive experimental studies demonstrate the gain of modeling multiple clicks and their dependencies. Finally, we note that since our experimental setup does not rely on tweaking search result rankings, it can be easily adopted by future studies.},
	author = {Guo, Fan and Liu, Chao and Wang, Yi Min Ym},
	doi = {10.1145/1498759.1498818},
	isbn = {9781605583907},
	journal = {Proceedings of the Second ACM International Conference on Web Search and Data Mining},
	keywords = {DCM,IR,click log analysis,statistical models,web search},
	mendeley-tags = {DCM,IR},
	pages = {124--131},
	title = {{Efficient multiple-click models in web search}},
	url = {http://dl.acm.org/citation.cfm?id=1498818},
	year = {2009}
}

@article{Chapelle2009,
	abstract = {As with any application of machine learning, web search ranking requires labeled data. The labels usually come in the form of relevance assessments made by editors. Click logs can also provide an important source of implicit feed- back and can be used as a cheap proxy for editorial labels. The main difficulty however comes from the so called posi- tion bias â€” urls appearing in lower positions are less likely to be clicked even if they are relevant. In this paper, we propose a Dynamic Bayesian Network which aims at pro- viding us with unbiased estimation of the relevance from the click logs. Experiments show that the proposed click model outperforms other existing click models in predicting both click-through rate and relevance. Categories},
	author = {Chapelle, Olivier and Zhang, Ya},
	isbn = {9781605584874},
	journal = {Www},
	keywords = {DBN,click modeling,click-through rate,dynamic bayesian network,ranking,web search},
	mendeley-tags = {DBN},
	pages = {1--10},
	title = {{A Dynamic Bayesian Network Click Model for Web Search Ranking Categories and Subject Descriptors}},
	year = {2009}
}

@article{Zhang2011,
	abstract = {Recent advances in search users' click modeling consider both users' search queries and click/skip behavior on documents to infer the user's perceived relevance. Most of these models, including dynamic Bayesian networks (DBN) and user browsing models (UBM), use probabilistic models to understand user click behavior based on individual queries. The user behavior is more complex when her actions to satisfy her information needs form a search session, which may include multiple queries and subsequent click behaviors on various items on search result pages. Previous research is limited to treating each query within a search session in isolation, without paying attention to their dynamic interactions with other queries in a search session. Investigating this problem, we consider the sequence of queries and their clicks in a search session as a task and propose a task-centric click model\~{}(TCM). TCM characterizes user behavior related to a task as a collective whole. Specifically, we identify and consider two new biases in TCM as the basis for user modeling. The first indicates that users tend to express their information needs incrementally in a task, and thus perform more clicks as their needs become clearer. The other illustrates that users tend to click fresh documents that are not included in the results of previous queries. Using these biases, TCM is more accurately able to capture user search behavior. Extensive experimental results demonstrate that by considering all the task information collectively, TCM can better interpret user click behavior and achieve significant improvements in terms of ranking metrics of NDCG and perplexity.},
	author = {Zhang, Yuchen and Chen, Weizhu and Wang, Dong and Yang, Qiang},
	doi = {10.1145/2020408.2020613},
	isbn = {9781450308137},
	journal = {Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '11},
	keywords = {IR,TCM,click log analysis,task-centric click model},
	mendeley-tags = {TCM,IR},
	pages = {1388},
	title = {{User-click modeling for understanding and predicting search-behavior}},
	url = {http://dl.acm.org/citation.cfm?doid=2020408.2020613},
	year = {2011}
}

@article{Dupret2008,
	abstract = {Search engine click logs provide an invaluable source of relevance information but this information is biased because we ignore which documents from the result list the users have actually seen before and after they clicked. Otherwise, we could estimate document relevance by simple counting. In this paper, we propose a set of assumptions on user browsing behavior that allows the estimation of the probability that a document is seen, thereby providing an unbiased estimate of document relevance. To train, test and compare our model to the best alternatives described in the Literature, we gather a large set of real data and proceed to an extensive cross-validation experiment. Our solution outperforms very significantly all previous models. As a side effect, we gain insight into the browsing behavior of users and we can compare it to the conclusions of an eye-tracking experiments by Joachims et al. [12]. In particular, our findings confirm that a user almost always see the document directly after a clicked document. They also explain why documents situated just after a very relevant document are clicked more often.},
	author = {Dupret, Georges E and Piwowarski, Benjamin},
	doi = {10.1145/1390334.1390392},
	isbn = {9781605581644},
	journal = {Sigir '08},
	keywords = {IR,UBM,behavior,engine,information,interaction,model,retrieval,search,user},
	mendeley-tags = {UBM,IR},
	pages = {331--338},
	title = {{A user browsing model to predict search engine click data from past observations.}},
	year = {2008}
}

@online{yandex,
	author = {Yandex LLC},
	title = {Task and Datasets},
	timestamp = {2015-01-15T14:17:30.000+0100},
	url = {http://imat-relpred.yandex.ru/en/datasets},
	year = {n.d}
}

@online{PyClick,
	author = {Ilya Markov},
	title = {Click Models for Web and Aggregated Search},
	url = {https://github.com/markovi/PyClick},
	year = {2015}
}

@article{NDCG,
  added-at = {2012-10-30T13:53:42.000+0100},
  author = {J{\"a}rvelin, K. and Kek{\"a}l{\"a}inen, J.},
  biburl = {http://www.bibsonomy.org/bibtex/24470d8a6a0b1a92d3d2ca35f1e4c28dd/folke},
  interhash = {b77acaebbbeb808f20fd7efef6d5f9e0},
  intrahash = {4470d8a6a0b1a92d3d2ca35f1e4c28dd},
  journal = {ACM Transactions on Information Systems (TOIS)},
  keywords = {cumulative dcg discounted evaluation gain ndcg recommendation recommender},
  number = 4,
  pages = {422--446},
  publisher = {ACM},
  timestamp = {2012-10-30T13:53:42.000+0100},
  title = {Cumulated gain-based evaluation of IR techniques},
  url = {http://scholar.google.de/scholar.bib?q=info:6Bdw8cs-UYMJ:scholar.google.com/&output=citation&hl=de&as_sdt=0,5&ct=citation&cd=0},
  volume = 20,
  year = 2002
}

@inproceedings{eye_track,
 author = {Joachims, Thorsten and Granka, Laura and Pan, Bing and Hembrooke, Helene and Gay, Geri},
 title = {Accurately Interpreting Clickthrough Data As Implicit Feedback},
 booktitle = {Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '05},
 year = {2005},
 isbn = {1-59593-034-5},
 location = {Salvador, Brazil},
 pages = {154--161},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1076034.1076063},
 doi = {10.1145/1076034.1076063},
 acmid = {1076063},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {WWW search, clickthrough, eyetracking, implicit feedback},
} 

@article{Kempe2008,
	abstract = {One of the most important yet insufficiently studied issues in online advertising is the externality effect among ads: the value of an ad impression on a page is affected not just by the location that the ad is placed in, but also by the set of other ads displayed on the page. For instance, a high quality competing ad can detract users from another ad, while a low quality ad could cause the viewer to abandon the page altogether. In this paper, we propose and analyze a model for externalities in sponsored search ads. Our model is based on the assumption that users will visually scan the list of ads from the top to the bottom. After each ad, they make independent random decisions with ad-specific probabilities on whether to continue scanning. We then generalize the model in two ways: allowing for multiple separate blocks of ads, and allowing click probabilities to explicitly depend on ad positions as well. For the most, basic model, we present a polynomial-time incentive-compatible auction mechanism for allocating and pricing ad slots. For the generalizations, we give approximation algorithms for the allocation of ads.},
	author = {Kempe, David and Mahdian, Mohammad},
	doi = {10.1007/978-3-540-92185-1\_65},
	isbn = {3540921842},
	issn = {03029743},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	keywords = {CM,Cascade Model},
	mendeley-tags = {CM,Cascade Model},
	pages = {585--596},
	title = {{A cascade model for externalities in sponsored search}},
	volume = {5385 LNCS},
	year = {2008}
}

@article{Craswell2008,
	abstract = {Search engine click logs provide an invaluable source of relevance information, but this information is biased. A key source of bias is presentation order: the probability of click is influenced by a document's position in the results page. This paper focuses on explaining that bias, modelling how probability of click depends on position. We propose four simple hypotheses about how position bias might arise. We carry out a large data-gathering effort, where we perturb the ranking of a major search engine, to see how clicks are affected. We then explore which of the four hypotheses best explains the real-world position effects, and compare these to a simple logistic regression model. The data are not well explained by simple position models, where some users click indiscriminately on rank 1 or there is a simple decay of attention over ranks. A 'cascade' model, where users view results from top to bottom and leave as soon as they see a worthwhile document, is our best explanation for position bias in early ranks},
	author = {Craswell, Nick and Zoeter, Onno and Taylor, Michael and Ramsey, Bill},
	doi = {10.1145/1341531.1341545},
	isbn = {9781595939279},
	journal = {Proceedings of the 2008 \ldots},
	keywords = {2,a search,click data,explaining position bias,for how users view,models,user behavior,we present several hypotheses,web search},
	pages = {87},
	title = {{An experimental comparison of click position-bias models}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.1288\&rep=rep1\&type=pdf$\backslash$nhttp://dl.acm.org/citation.cfm?id=1341545},
	year = {2008}
}

@article{Guo2009_CCM,
	abstract = {Given a terabyte click log, can we build an efficient and effective click model? It is commonly believed that web search click logs are a gold mine for search business, because they reflect users' preference over web documents presented by the search engine. Click models provide a principled approach to inferring user-perceived relevance of web documents, which can be leveraged in numerous applications in search businesses. Due to the huge volume of click data, scalability is a must. We present the click chain model (CCM), which is based on a solid, Bayesian framework. It is both scalable and incremental, perfectly meeting the computational challenges imposed by the voluminous click logs that constantly grow. We conduct an extensive experimental study on a data set containing 8.8 million query sessions obtained in July 2008 from a commercial search engine. CCM consistently outperforms two state-of-the-art competitors in a number of metrics, with over 9.7\% better log-likelihood, over 6.2\% better click perplexity and much more robust (up to 30\%) prediction of the first and the last clicked position.},
	author = {Guo, Fan and Liu, Chao and Kannan, Anitha and Minka, Tom and Taylor, Michael and Wang, Yi-Min Min and Faloutsos, Christos},
	doi = {10.1145/1526709.1526712},
	isbn = {9781605584874},
	journal = {Proceedings of the 18th international conference on World wide web - WWW '09},
	keywords = {CCM},
	mendeley-tags = {CCM},
	pages = {11},
	title = {{Click chain model in web search}},
	url = {http://portal.acm.org/citation.cfm?doid=1526709.1526712$\backslash$nhttp://portal.acm.org/citation.cfm?id=1526709.1526712},
	year = {2009}
}
