\section{Introduction}
Modeling user behavior on a search engine result page is important for understanding users and supporting simulation experiments.
As result pages become more complex, click models have to evolve as well in order to capture additional aspects of user behavior in response to new forms of result presentation.
In recent years many models have been proposed that are aimed at predicting behaviour of web search users. 

In this project, we implement and evaluate different click models using multiple evaluation metrics and report on the performance of these click models.
The click models include the Click-Through Rate click model (CTR), Position-Based click model (PBM), Cascade click model (CM) \cite{Kempe2008}, \fixme{Dependent Click Model (DCM) \cite{Guo2009_DCM}, Dynamic Bayesian Network click model (DBN) \cite{Chapelle2009}}, User Browsing Model (UBM) \cite{Dupret2008}, Click Chain Model (CCM) \cite{Guo2009_CCM} and Task-centric Click Model (TCM) \cite{Zhang2011}.
The evaluation metrics we use to evaluate performance of these click models are loglikelihood, perplexity, click-through-rate prediction, relevance prediction, ranking performance and computation time. We will also analyze two different factors that might influence performance of the click models, query frequency and click entropy.
By doing this experiment we will know the performance of each different click model and this information can be helpful in the creation of new click models and used as a performance benchmark of new click model proposals.

%report organization
This report is organized as follows.
In Section~\ref{sec:methodology} we will describe different click models and evaluation algorithms used in our experiments.
The experiments and data source information will be covered in Section~\ref{sec:evaluation}, followed by an analysis of these experiments in Section~\ref{sec:analysis}.
